# Archive Detective Backend

Production-grade FastAPI backend for deep research and batch processing of Trove archives.

## ğŸš€ Quick Start

```bash
# 1. Setup environment
./setup.sh

# 2. Configure API key
# Edit .env and set TROVE_API_KEY=your_key_here

# 3. Run server
./run.sh

# Server runs on http://127.0.0.1:8000
```

## ğŸ“‹ Prerequisites

- Python 3.9+
- TROVE_API_KEY from https://trove.nla.gov.au/about/create-something/using-api/

## ğŸ”§ Setup

```bash
# Install dependencies
./setup.sh

# Configure environment
cp .env.example .env
# Edit .env and set TROVE_API_KEY
```

## ğŸƒ Running

```bash
# Start server
./run.sh

# Or manually:
source venv/bin/activate
uvicorn app.main:app --host 127.0.0.1 --port 8000 --reload
```

## ğŸ§ª Testing

```bash
# Run smoke tests
./smoke.sh

# This will:
# 1. Start server
# 2. Start a batch research job
# 3. Poll until complete
# 4. Fetch report, markdown, evidence
# 5. Run validator
# 6. Check assertions
```

## ğŸ“¡ API Endpoints

### Deep Research

- `POST /api/research/deep` - Immediate deep research (smaller runs)
- `POST /api/research/deep/stream` - Streaming deep research (SSE)

### Batch Research

- `POST /api/research/start-batch` - Start background batch job
- `GET /api/research/job/{job_id}` - Get job status
- `GET /api/research/job/{job_id}/report` - Get verified report JSON
- `GET /api/research/job/{job_id}/markdown` - Get report as Markdown
- `GET /api/research/job/{job_id}/evidence` - Get evidence as JSONL

### Search & Reader

- `GET /search?q=...` - Search page with results
- `GET /reader?id=...` - Article reader page
- `GET /research?seed=...` - Deep research page

### Dashboard

- `GET /dashboard` - Dashboard HTML
- `GET /api/dashboard` - Dashboard JSON

### Other

- `GET /search?q=...` - Search API (JSON)
- `POST /api/tts/stream` - TTS endpoint (501 Not Implemented stub)

## ğŸ“Š Database

SQLite database (`troveing.sqlite`) with:
- `jobs` - Batch research jobs
- `sources` - Ingested Trove articles
- `sources_fts` - FTS5 full-text search index

## ğŸ” Example: Iluka Research

```bash
# Start batch job
curl -X POST http://127.0.0.1:8000/api/research/start-batch \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Iluka mineral sands rutile zircon (Clarence River, NSW)",
    "years_from": 1945,
    "years_to": 1980,
    "max_pages": 12,
    "page_size": 100,
    "state": "New South Wales"
  }'

# Get job ID from response, then:
JOB_ID="your-job-id"

# Check status
curl http://127.0.0.1:8000/api/research/job/$JOB_ID

# Get report (when done)
curl http://127.0.0.1:8000/api/research/job/$JOB_ID/report > report.json

# Get markdown
curl http://127.0.0.1:8000/api/research/job/$JOB_ID/markdown > report.md

# Get evidence
curl http://127.0.0.1:8000/api/research/job/$JOB_ID/evidence > evidence.jsonl

# Validate
python3 validate_report.py report.json
```

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI app
â”‚   â”œâ”€â”€ db.py                # SQLite + FTS5
â”‚   â”œâ”€â”€ routers/             # API routes
â”‚   â”‚   â”œâ”€â”€ deep_research.py
â”‚   â”‚   â”œâ”€â”€ batch_research.py
â”‚   â”‚   â”œâ”€â”€ dashboard.py
â”‚   â”‚   â”œâ”€â”€ formatting.py
â”‚   â”‚   â””â”€â”€ search_reader.py
â”‚   â”œâ”€â”€ services/            # Business logic
â”‚   â”‚   â”œâ”€â”€ deep_research.py
â”‚   â”‚   â”œâ”€â”€ trove_batch.py
â”‚   â”‚   â”œâ”€â”€ trove_client.py
â”‚   â”‚   â””â”€â”€ stats.py
â”‚   â”œâ”€â”€ models/              # Pydantic models
â”‚   â”œâ”€â”€ templates/           # Jinja2 templates
â”‚   â””â”€â”€ static/              # Static files
â”œâ”€â”€ setup.sh                 # Setup script
â”œâ”€â”€ run.sh                   # Run script
â”œâ”€â”€ smoke.sh                 # Smoke tests
â”œâ”€â”€ validate_report.py       # Report validator
â”œâ”€â”€ .env.example             # Environment template
â””â”€â”€ requirements.txt         # Dependencies
```

## ğŸ”‘ Environment Variables

See `.env.example` for all options. Required:
- `TROVE_API_KEY` - Your Trove API key

Optional:
- `TROVEING_DB` - Database path (default: `troveing.sqlite`)
- `WEB_SEARCH_ENABLED` - Enable web search (default: `0`)
- `ALLOWED_ORIGINS` - CORS origins (comma-separated)

## ğŸ› Troubleshooting

### Server won't start
- Check `TROVE_API_KEY` is set in `.env`
- Check port 8000 is not in use: `lsof -i :8000`
- Check logs: `tail -f /tmp/troveing_server.log`

### Batch jobs fail
- Check Trove API key is valid
- Check network connectivity
- Review job error: `GET /api/research/job/{job_id}`

### Validator fails
- Ensure report has sources: `jq '.sources | length' report.json`
- Check evidence quotes â‰¤240 chars
- Verify citations resolve to sources

## ğŸ“ Logs

- Server logs: `/tmp/troveing_server.log` (when run via smoke.sh)
- Database: `troveing.sqlite` (SQLite WAL mode)

## ğŸ¯ Features

- âœ… Deep research with LLM synthesis
- âœ… Batch ingestion with SQLite FTS5
- âœ… BM25 ranking (normalized 0..1)
- âœ… Sentence-level evidence extraction
- âœ… State disambiguation (NSW vs WA)
- âœ… Verified reports (citations must resolve)
- âœ… Markdown/JSONL export
- âœ… Live metrics dashboard
- âœ… Automated validation

## ğŸ“š Documentation

- `BATCH_RESEARCH_README.md` - Batch research details
- `validate_report.py` - Report validation logic

